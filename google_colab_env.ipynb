{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ad98aa",
   "metadata": {},
   "source": [
    "# ML Reproducibility Challenge 2022\n",
    "## TS2Vec: Towards Universal Representation of Time Series\n",
    "\n",
    "The original paper can be found [here](https://arxiv.org/pdf/2106.10466.pdf)\n",
    "\n",
    "Original code implementation can be found on [github/](https://github.com/yuezhihan/ts2vec.git)\n",
    "\n",
    "ML Reproducibility Challenge 2022 [homepage](https://paperswithcode.com/rc2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yuezhihan/ts2vec.git # clones TS2Vec repo\n",
    "!python3 --version # want: 3.8.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791396f",
   "metadata": {},
   "source": [
    "## Preparing the Colab Environment\n",
    "\n",
    "Our Google Colab environment came with a python3.7 kernel installed. TS2Vec requires python3.8, so we had to preparing the environment accordingly. \n",
    "\n",
    "Make sure the runtime type is set to 'gpu'.\n",
    "\n",
    "Installs python3.8 and library requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install python3.8\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
    "!python3 --version # want: 3.8.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d579972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating python version breaks pip -- get pip\n",
    "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
    "!python3 get-pip.py\n",
    "\n",
    "# install requirements - their requirements.txt file didn't work\n",
    "!pip3 install torch\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit_learn==0.24.2\n",
    "!pip3 install bottleneck\n",
    "!pip3 install pandas\n",
    "!pip3 install statsmodels\n",
    "!pip3 install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ts2vec # change directory to cloned repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069844e4",
   "metadata": {},
   "source": [
    "## Reproducing paper results\n",
    "\n",
    "Performance metrics presented in the results section can be reproduced by running TS2Vec packaged functions provided in the $\\texttt{scripts/}$ folder.\n",
    "\n",
    "Datasets must be manually prepared according to instructions in the TS2Vec $\\texttt{README.md}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample reproduction line\n",
    "!python3 -u train.py ETTh1 forecast_univar --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5df8db",
   "metadata": {},
   "source": [
    "## Running TS2Vec on a new dataset\n",
    "\n",
    "The dataset is of normalized hydrologic data (groundwater depth and local precipitation) measured over the course of 3 months (June-September 2021). \n",
    "\n",
    "If using Google Colab, you'll need to upload the data to the $\\texttt{datasets/}$ folder before running the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run TS2Vec forecasting on hydrologic dataset with all default parameters\n",
    "!python3 train.py norm_002B_rain newdata_run --loader forecast_csv --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3d10b",
   "metadata": {},
   "source": [
    "## Visualizing Forecasting Performance\n",
    "\n",
    "To visualize the forecast predicitons, we had to modify several functions from the $\\texttt{tasks/}$ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff89a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from TS2Vec \n",
    "from ts2vec import TS2Vec\n",
    "from tasks.forecasting import eval_forecasting, generate_pred_samples, cal_metrics\n",
    "\n",
    "# import libraries\n",
    "import datautils\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32474f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We modified fit_ridge(), the function that fits a Ridge Regression optimizer for the forecasting task\n",
    "in order to allow a choice of a wider range of alpha values (parameter to Ridge()). \n",
    "'''\n",
    "def fit_ridge(train_features, train_y, valid_features, valid_y, MAX_SAMPLES=100000):\n",
    "    # If the training set is too large, subsample MAX_SAMPLES examples\n",
    "    if train_features.shape[0] > MAX_SAMPLES:\n",
    "        split = train_test_split(\n",
    "            train_features, train_y,\n",
    "            train_size=MAX_SAMPLES, random_state=0\n",
    "        )\n",
    "        train_features = split[0]\n",
    "        train_y = split[2]\n",
    "    if valid_features.shape[0] > MAX_SAMPLES:\n",
    "        split = train_test_split(\n",
    "            valid_features, valid_y,\n",
    "            train_size=MAX_SAMPLES, random_state=0\n",
    "        )\n",
    "        valid_features = split[0]\n",
    "        valid_y = split[2]\n",
    "    \n",
    "    alphas = [0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 30, 40, 50, 75, 100, 150, 200, 250, 300, 350, 400, 450, 500, \\\n",
    "              550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "    valid_results = []\n",
    "    # chooses the alpha with the best score\n",
    "    for alpha in alphas:\n",
    "        lr = Ridge(alpha=alpha).fit(train_features, train_y)\n",
    "        valid_pred = lr.predict(valid_features)\n",
    "        score = np.sqrt(((valid_pred - valid_y) ** 2).mean()) + np.abs(valid_pred - valid_y).mean()\n",
    "        valid_results.append(score)\n",
    "    best_alpha = alphas[np.argmin(valid_results)]\n",
    "    print(\"this is the best alpha ever: \", best_alpha)\n",
    "    \n",
    "    lr = Ridge(alpha=best_alpha)\n",
    "    lr.fit(train_features, train_y)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modified the eval_forecasting() function to return the actual test prediction and labels, which \n",
    "previously weren't accessible. \n",
    "'''\n",
    "def mod_eval_forecasting(model, data, train_slice, valid_slice, test_slice, scaler, pred_lens, \n",
    "                         n_covariate_cols, sliding_length=1, padding=200,batch_size=256):\n",
    "    \n",
    "    t = time.time()\n",
    "    all_repr = model.encode(\n",
    "        data,\n",
    "        casual=True,\n",
    "        sliding_length=sliding_length,\n",
    "        sliding_padding=padding,\n",
    "        batch_size=batch_size \n",
    "    )\n",
    "    ts2vec_infer_time = time.time() - t\n",
    "    \n",
    "    train_repr = all_repr[:, train_slice]\n",
    "    valid_repr = all_repr[:, valid_slice]\n",
    "    test_repr = all_repr[:, test_slice]\n",
    "    \n",
    "    train_data = data[:, train_slice, n_covariate_cols:]\n",
    "    valid_data = data[:, valid_slice, n_covariate_cols:]\n",
    "    test_data = data[:, test_slice, n_covariate_cols:]\n",
    "    \n",
    "    ours_result = {}\n",
    "    lr_train_time = {}\n",
    "    lr_infer_time = {}\n",
    "    out_log = {}\n",
    "    collect_test_pred = {}\n",
    "    collect_test_labels = {}\n",
    "    for pred_len in pred_lens:\n",
    "        print(\"pred_len\", pred_len)\n",
    "        train_features, train_labels = generate_pred_samples(train_repr, train_data, pred_len, drop=padding)\n",
    "        valid_features, valid_labels = generate_pred_samples(valid_repr, valid_data, pred_len)\n",
    "        test_features, test_labels = generate_pred_samples(test_repr, test_data, pred_len)\n",
    "        \n",
    "        t = time.time()\n",
    "        lr = fit_ridge(train_features, train_labels, valid_features, valid_labels)\n",
    "        lr_train_time[pred_len] = time.time() - t\n",
    "        \n",
    "        t = time.time()\n",
    "        test_pred = lr.predict(test_features)\n",
    "        lr_infer_time[pred_len] = time.time() - t\n",
    "\n",
    "        ori_shape = test_data.shape[0], -1, pred_len, test_data.shape[2]\n",
    "        test_pred = test_pred.reshape(ori_shape)\n",
    "        test_labels = test_labels.reshape(ori_shape)\n",
    "        collect_test_pred[pred_len] = test_pred\n",
    "        collect_test_labels[pred_len] = test_labels\n",
    "\n",
    "    return collect_test_pred, collect_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f6737",
   "metadata": {},
   "source": [
    "## Training models\n",
    "\n",
    "We ran a hyperparameter search, documented in the commented out lines below. Model files are not included here, but can reproduced by training a new model with the specified arguments and then modifying the file name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py norm_002B_rain forecast_multivar --loader forecast_csv --repr-dims 120 --epochs 800 --eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_type = \"multi\"\n",
    " \n",
    "if model_type == \"multi\" :\n",
    "    in_dim = 10\n",
    "\n",
    " #### MODIFYING REPR-DIMS ###\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_183101/model.pkl'#repr-dims=50\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_182755/model.pkl'#repr-dims=100\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_182047/model.pkl'#repr-dims=120\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_183334/model.pkl'#repr-dims=160\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_183549/model.pkl'#repr-dims=320\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_183849/model.pkl'#repr-dims=640\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_184141/model.pkl'#repr-dims=1280\n",
    "\n",
    " ### MODIFYING EPOCHS WITH REPR-DIM=120 ###\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_184705/model.pkl'#repr-dims=100, epochs=400\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_184952/model.pkl'#repr-dims=120, epochs=600\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_185230/model.pkl'#repr-dims=120, epochs=800\n",
    " \n",
    " ### MODIFYING LR WITH REPR-DIM=120 EPOCHS=400 ###\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_185750/model.pkl'#repr-dims=120, epochs=400, lr=0.0001\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_190131/model.pkl'#repr-dims=120, epochs=800, lr=0.01\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_190401/model.pkl'#repr-dims=120, epochs=400, lr=0.1\n",
    "\n",
    " ### MODIFYING MAX TRAIN LENGTH REPR-DIM=120 EPOCHS=400 LR=(DEFAULT) ###\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_190812/model.pkl'#repr-dims=120, epochs=400, mtl=500\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_191052/model.pkl'#repr-dims=120, epochs=400, mtl=1000\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_191326/model.pkl'#repr-dims=120, epochs=400, mtl=4000\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_191603/model.pkl'#repr-dims=120, epochs=400, mtl=5000\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_191839/model.pkl'#repr-dims=120, epochs=400, mtl=6000\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_192112/model.pkl'#repr-dims=120, epochs=400, mtl=8000\n",
    " \n",
    " ### MODIFYING alpha in the losses.py hierarchical contrastive loss \n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_192832/model.pkl' #--repr-dims 120 --epochs 800, alpha = 0.9\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_193237/model.pkl' #--repr-dims 120 --epochs 800, alpha = 0.99\n",
    "#  file_path = 'training/norm_002B_rain__forecast_multivar_20221209_193556/model.pkl' #--repr-dims 120 --epochs 800, alpha = 0.1\n",
    "file_path = 'training/norm_002B_rain__forecast_multivar_20221209_193912/model.pkl' #--repr-dims 120 --epochs 800, alpha = 0.01\n",
    "\n",
    "rep = 120\n",
    "is_univar = False\n",
    "model = TS2Vec(input_dims=in_dim, output_dims=rep)\n",
    "\n",
    "elif model_type == \"uni\" :\n",
    "    in_dim = 8\n",
    "    file_path = 'training/hey_002B_rain__forecast_multivar_20221201_203016/model.pkl'\n",
    "    is_univar = True\n",
    "    model = TS2Vec(input_dims=in_dim)\n",
    "\n",
    "model.load(file_path)\n",
    "\n",
    "# prepare the datasets\n",
    "data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols = datautils.load_forecast_csv('norm_002B_rain', univar=is_univar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755f368",
   "metadata": {},
   "source": [
    "### Visualize the data input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e280558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time-encoded input data\n",
    "fig, ax = plt.subplots(figsize=(12,6),nrows=2, sharex=True)\n",
    "x = np.linspace(0,data.shape[1]-1, data.shape[1])\n",
    "ax[0].scatter(x, data[0,:,-1], marker='.')\n",
    "ax[0].set_title(\"Original Groundwater Timeseries\")\n",
    "for i in range(in_dim):\n",
    "    ax[1].scatter(x, data[0,:,i], marker='.', alpha=0.5, label=i)\n",
    "ax[1].set_title(\"Expanded dimensional data\")\n",
    "ax[1].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747b12c",
   "metadata": {},
   "source": [
    "### Fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644de938",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = 1\n",
    "p=200\n",
    "bs = 256\n",
    "test_pred, test_labels = mod_eval_forecasting(model, data, train_slice, valid_slice, test_slice, scaler, pred_lens, \n",
    "                                              n_covariate_cols, sliding_length=sl, padding=p, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972345b3",
   "metadata": {},
   "source": [
    "### Plot the best slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value in test_pred[] and test_labels[] is the H in pred length\n",
    "# selcet final dimension\n",
    "dim_slice = -1\n",
    "\n",
    "# plot prediction forecast for all pred_lengths\n",
    "fig, ax = plt.subplots(figsize=(12,8),nrows=len(pred_lens), sharex=True, sharey=False)\n",
    "\n",
    "for iter, h in enumerate(pred_lens):\n",
    "    preds = test_pred[h]\n",
    "    labs = test_labels[h]\n",
    "    # use the slice that has the lowest difference between lables and predictions\n",
    "    diffs = np.sum(np.abs(labs-preds), axis = (0,2))\n",
    "    # get the best slice index for each n_covariant_col\n",
    "    best_pred_inds = np.argmin(diffs, axis = 0)\n",
    "    best_pred_ind = best_pred_inds[-1]\n",
    "    # time steps\n",
    "    t = np.arange(h) \n",
    "\n",
    "    ax[iter].plot(t, labs[0,best_pred_ind,:,dim_slice], label = 'Ground Truth', linewidth=6)\n",
    "    ax[iter].plot(t,  preds[0,best_pred_ind,:,dim_slice], marker='.', c='orange', label='TS2Vec')\n",
    "    ax[iter].set_title('Prediction, pred_length=%i, ' %h + 'slice=%i'%best_pred_ind)\n",
    "ax[-1].set_xlabel('Forecasting step')\n",
    "ax[0].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fe5d0",
   "metadata": {},
   "source": [
    "### Plot an interesting slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value in test_pred[] and test_labels[] is the H in pred length\n",
    "# selcet final dimension\n",
    "dim_slice = -1\n",
    "\n",
    "# plot prediction forecast for all pred_lengths\n",
    "fig, ax = plt.subplots(figsize=(12,8),nrows=len(pred_lens), sharex=True, sharey=False)\n",
    "\n",
    "for iter, h in enumerate(pred_lens):\n",
    "    preds = test_pred[h]\n",
    "    labs = test_labels[h]\n",
    "    best_pred_ind = 1300\n",
    "    # time steps\n",
    "    t = np.arange(h) \n",
    "\n",
    "    ax[iter].plot(t, labs[0,best_pred_ind,:,dim_slice], label = 'Ground Truth', linewidth=6)\n",
    "    ax[iter].plot(t,  preds[0,best_pred_ind,:,dim_slice], marker='.', c='orange', label='TS2Vec')\n",
    "    ax[iter].set_title('Prediction, pred_length=%i, ' %h + 'slice=%i'%best_pred_ind)\n",
    "ax[-1].set_xlabel('Forecasting step')\n",
    "ax[0].legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
